# Distributed Key-Value Store

Há»‡ thá»‘ng lÆ°u trá»¯ dáº¡ng key-value phÃ¢n tÃ¡n vá»›i kháº£ nÄƒng chá»‹u lá»—i vÃ  sao lÆ°u dá»¯ liá»‡u tá»± Ä‘á»™ng.

## ğŸ“‹ Má»¥c lá»¥c

- [TÃ­nh nÄƒng](#tÃ­nh-nÄƒng)
- [Kiáº¿n trÃºc](#kiáº¿n-trÃºc)
- [CÃ i Ä‘áº·t](#cÃ i-Ä‘áº·t)
- [Sá»­ dá»¥ng](#sá»­-dá»¥ng)
- [Testing](#testing)
- [TÃ i liá»‡u ká»¹ thuáº­t](#tÃ i-liá»‡u-ká»¹-thuáº­t)

## âœ¨ TÃ­nh nÄƒng

### Chá»©c nÄƒng cÆ¡ báº£n
- **PUT(key, value)**: LÆ°u trá»¯ cáº·p key-value
- **GET(key)**: Láº¥y giÃ¡ trá»‹ cá»§a key
- **DELETE(key)**: XÃ³a key

### TÃ­nh nÄƒng nÃ¢ng cao
- âœ… **PhÃ¢n tÃ¡n dá»¯ liá»‡u**: Sá»­ dá»¥ng Consistent Hashing
- âœ… **Sao lÆ°u tá»± Ä‘á»™ng**: Replication factor = 2
- âœ… **Chá»‹u lá»—i**: Hoáº¡t Ä‘á»™ng khi cÃ³ node bá»‹ há»ng
- âœ… **Tá»± phÃ¡t hiá»‡n lá»—i**: Heartbeat mechanism
- âœ… **Tá»± khÃ´i phá»¥c**: Data recovery khi node restart
- âœ… **Chuyá»ƒn tiáº¿p yÃªu cáº§u**: Request forwarding tá»± Ä‘á»™ng

## ğŸ—ï¸ Kiáº¿n trÃºc

### MÃ´ hÃ¬nh tá»•ng thá»ƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Client Layer                  â”‚
â”‚  (PUT, GET, DELETE operations)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼            â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node 1 â”‚  â”‚ Node 2 â”‚  â”‚ Node 3 â”‚
â”‚ :5001  â”‚â—„â”€â”¤ :5002  â”‚â—„â”€â”¤ :5003  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
     â”‚           â”‚           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        Heartbeat & Replication
```

### CÃ¡c thÃ nh pháº§n chÃ­nh

1. **Node (node.py)**
   - Quáº£n lÃ½ dá»¯ liá»‡u local
   - Xá»­ lÃ½ requests tá»« client
   - Tham gia cluster
   - Gá»­i/nháº­n heartbeat
   - Sao lÆ°u dá»¯ liá»‡u

2. **Client (client.py)**
   - Giao diá»‡n tÆ°Æ¡ng tÃ¡c
   - Káº¿t ná»‘i Ä‘áº¿n báº¥t ká»³ node nÃ o
   - Retry logic khi node fail

3. **Consistent Hashing**
   - PhÃ¢n vÃ¹ng dá»¯ liá»‡u Ä‘á»u
   - Minimize data movement khi thÃªm/xÃ³a node

## ğŸš€ CÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng
- Python 3.7+
- KhÃ´ng cáº§n thÆ° viá»‡n bÃªn ngoÃ i (chá»‰ dÃ¹ng standard library)

### Cáº¥u trÃºc thÆ° má»¥c

```
distributed-kv-store/
â”œâ”€â”€ node.py              # Node implementation
â”œâ”€â”€ client.py            # Client interface
â”œâ”€â”€ start_cluster.py     # Cluster launcher
â”œâ”€â”€ test_system.py       # Test suite
â””â”€â”€ README.md            # Documentation
```

### CÃ i Ä‘áº·t

```bash
# Clone hoáº·c táº£i project
git clone <repository-url>
cd distributed-kv-store

# KhÃ´ng cáº§n cÃ i Ä‘áº·t thÃªm gÃ¬!
```

## ğŸ“– Sá»­ dá»¥ng

### 1. Khá»Ÿi Ä‘á»™ng Cluster

**CÃ¡ch 1: Sá»­ dá»¥ng script tá»± Ä‘á»™ng**

```bash
# Start 3 nodes trÃªn ports 5001-5003
python start_cluster.py

# Start 5 nodes
python start_cluster.py 5

# Start 3 nodes tá»« port 6000
python start_cluster.py 3 6000
```

**CÃ¡ch 2: Khá»Ÿi Ä‘á»™ng thá»§ cÃ´ng**

Terminal 1 - Node 1:
```python
from node import Node
import threading

node1 = Node("node1", "localhost", 5001)
threading.Thread(target=node1.start).start()
```

Terminal 2 - Node 2:
```python
from node import Node
import threading

node2 = Node("node2", "localhost", 5002)
threading.Thread(target=node2.start).start()
node2.join_cluster("localhost", 5001)
```

Terminal 3 - Node 3:
```python
from node import Node
import threading

node3 = Node("node3", "localhost", 5003)
threading.Thread(target=node3.start).start()
node3.join_cluster("localhost", 5001)
```

### 2. Sá»­ dá»¥ng Client

**Interactive mode:**

```bash
python client.py
```

Sau Ä‘Ã³ nháº­p commands:
```
> PUT name Alice
âœ“ PUT name = Alice

> GET name
âœ“ GET name = Alice

> DELETE name
âœ“ DELETE name

> QUIT
```

**Programmatic usage:**

```python
from client import KVStoreClient

# Káº¿t ná»‘i Ä‘áº¿n cluster
client = KVStoreClient([
    ("localhost", 5001),
    ("localhost", 5002),
    ("localhost", 5003)
])

# Thá»±c hiá»‡n operations
client.put("user:1", "Alice")
value = client.get("user:1")
client.delete("user:1")
```

### 3. Testing

```bash
# Cháº¡y full test suite
python test_system.py
```

Test suite bao gá»“m:
- âœ… Basic operations (PUT, GET, DELETE)
- âœ… Cluster formation
- âœ… Data replication
- âœ… Fault tolerance
- âœ… Node recovery

## ğŸ”§ TÃ i liá»‡u ká»¹ thuáº­t

### Giao thá»©c truyá»n thÃ´ng

**Format**: JSON qua TCP socket

**Message structure:**
```json
{
  "command": "PUT|GET|DELETE|JOIN|HEARTBEAT|REPLICATE",
  "key": "string",
  "value": "string",
  "node_id": "string",
  "host": "string",
  "port": 5001
}
```

**Response structure:**
```json
{
  "status": "success|error",
  "value": "string",
  "message": "string"
}
```

### Consistent Hashing

Má»—i key vÃ  node Ä‘Æ°á»£c hash thÃ nh má»™t sá»‘ nguyÃªn:
```python
hash(key) = MD5(key) mod 2^128
hash(node_id) = MD5(node_id) mod 2^128
```

Dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u trÃªn node cÃ³ hash nhá» nháº¥t >= hash(key) trÃªn ring.

### Replication Strategy

**Primary-Backup model:**
- Má»—i key cÃ³ 2 replicas (replication_factor = 2)
- Primary node: node Ä‘áº§u tiÃªn responsible
- Backup node: node tiáº¿p theo trÃªn ring

**Write flow:**
1. Client gá»­i PUT Ä‘áº¿n báº¥t ká»³ node nÃ o
2. Node kiá»ƒm tra trÃ¡ch nhiá»‡m
3. Náº¿u khÃ´ng responsible â†’ forward Ä‘áº¿n primary node
4. Primary node lÆ°u local
5. Primary node replicate Ä‘áº¿n backup node

**Read flow:**
1. Client gá»­i GET Ä‘áº¿n báº¥t ká»³ node nÃ o
2. Node kiá»ƒm tra trÃ¡ch nhiá»‡m
3. Náº¿u cÃ³ data â†’ return ngay
4. Náº¿u khÃ´ng â†’ forward Ä‘áº¿n responsible node

### Failure Detection

**Heartbeat mechanism:**
- Má»—i node gá»­i heartbeat má»—i 3 giÃ¢y
- Timeout: 10 giÃ¢y
- Náº¿u khÃ´ng nháº­n heartbeat trong 10s â†’ node bá»‹ coi lÃ  failed

**Node failure handling:**
```
Node fail â†’ Removed from peer list â†’ Requests routed to replicas
```

### Data Recovery

Khi node restart:
1. Join cluster láº¡i
2. Request full data snapshot tá»« peer
3. Filter data theo consistent hashing
4. Restore chá»‰ data mÃ  node responsible for

### Scalability

**ThÃªm node má»›i:**
```python
new_node = Node("node4", "localhost", 5004)
threading.Thread(target=new_node.start).start()
new_node.join_cluster("localhost", 5001)
```

Consistent hashing Ä‘áº£m báº£o:
- Chá»‰ ~1/N data cáº§n di chuyá»ƒn
- Minimize disruption

## ğŸ“Š Performance Characteristics

| Operation | Complexity | Notes |
|-----------|------------|-------|
| PUT | O(R) | R = replication factor |
| GET | O(1) | If local, O(1) network hop if forwarded |
| DELETE | O(R) | Same as PUT |
| Node failure detection | O(1) | Heartbeat based |
| Data recovery | O(D) | D = data size for node |

## ğŸ” Debugging

**Enable verbose logging:**
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

**Check node status:**
```python
print(f"Peers: {node.peers}")
print(f"Data: {node.data}")
print(f"Heartbeats: {node.last_heartbeat}")
```

## âš ï¸ Háº¡n cháº¿ hiá»‡n táº¡i

1. **KhÃ´ng cÃ³ persistence**: Dá»¯ liá»‡u chá»‰ trong memory
2. **Simple consistency model**: Eventual consistency
3. **No authentication**: KhÃ´ng cÃ³ security layer
4. **Fixed replication factor**: KhÃ´ng thá»ƒ thay Ä‘á»•i Ä‘á»™ng
5. **No data compaction**: KhÃ´ng cÃ³ garbage collection

## ğŸš€ Cáº£i tiáº¿n Ä‘á» xuáº¥t

### Ngáº¯n háº¡n
- [ ] ThÃªm disk persistence (write-ahead log)
- [ ] Implement quorum-based consistency
- [ ] Add authentication & authorization
- [ ] Metrics vÃ  monitoring

### DÃ i háº¡n
- [ ] Dynamic replication factor
- [ ] Automatic data rebalancing
- [ ] Support for transactions
- [ ] Compression
- [ ] Multi-datacenter support

## ğŸ“ License

MIT License - Free to use for educational purposes

## ğŸ‘¥ Contributors

Distributed Systems Course Project

---

**LÆ°u Ã½**: ÄÃ¢y lÃ  implementation Ä‘Æ¡n giáº£n cho má»¥c Ä‘Ã­ch há»c táº­p. KhÃ´ng nÃªn dÃ¹ng cho production environment.